{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-07T10:56:07.550749Z",
     "start_time": "2025-02-07T10:56:04.899017Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.preprocess import fast_clean_text, parallel_apply, process_texts\n",
    "\n",
    "column_names = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\User\\PycharmProjects\\sentiment\\data\\training.1600000.processed.noemoticon.csv', encoding='latin-1', names=column_names, header=None)\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment          id                          date     query  \\\n",
      "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
      "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
      "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
      "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
      "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
      "\n",
      "              user                                               text  \n",
      "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
      "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
      "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
      "4           Karoli  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T10:56:47.009344Z",
     "start_time": "2025-02-07T10:56:46.995897Z"
    }
   },
   "cell_type": "code",
   "source": "print(df[\"sentiment\"].value_counts())",
   "id": "eca1367a73f8575",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:57:27.388399Z",
     "start_time": "2025-02-07T11:57:27.136424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\User\\PycharmProjects\\sentiment\\data\\Twitter_Data.csv', encoding='latin-1')\n",
    "df1.rename(columns={'category':'sentiment'}, inplace=True)\n",
    "df1.rename(columns={'clean_text':'text'}, inplace=True)\n",
    "print(df1['sentiment'].value_counts())\n",
    "#df1 = df1[df1['sentiment'] != 'irrelevant']\n",
    "df1['sentiment'] = df1['sentiment'].map({-1:0,0:2,1:4})\n",
    "print(df1.head())"
   ],
   "id": "b85e88a22872833b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      " 1.0    72250\n",
      " 0.0    55213\n",
      "-1.0    35510\n",
      "Name: count, dtype: int64\n",
      "                                                text  sentiment\n",
      "0  when modi promised √¢¬Ä¬úminimum government maxim...        0.0\n",
      "1  talk all the nonsense and continue all the dra...        2.0\n",
      "2  what did just say vote for modi  welcome bjp t...        4.0\n",
      "3  asking his supporters prefix chowkidar their n...        4.0\n",
      "4  answer who among these the most powerful world...        4.0\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:57:33.695470Z",
     "start_time": "2025-02-07T11:57:33.578181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_combined = pd.concat([df[['text','sentiment']], df1[['text', 'sentiment']]] , ignore_index=True)\n",
    "print(df_combined['sentiment'].value_counts())\n",
    "#df_combined.to_csv(\"sentiment_combined.csv\", index=False)\n"
   ],
   "id": "b6adb659a753c4c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4.0    872250\n",
      "0.0    835510\n",
      "2.0     55213\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T13:17:35.163940Z",
     "start_time": "2025-02-07T13:17:34.493728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df_combined['text'] = df_combined['text'].astype(str)\n",
    "df_combined['text'] = df_combined['text'].fillna(\"\")\n",
    "print(df_combined[~df_combined['text'].apply(lambda x: isinstance(x, str))])\n",
    "\n"
   ],
   "id": "940fa8c103aedb4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T13:59:32.024648Z",
     "start_time": "2025-02-07T13:59:23.628134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.preprocess import  parallel_apply, process_texts\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "num_cores=mp.cpu_count() // 2\n",
    "df_combined = parallel_apply(df_combined,process_texts, num_cores)\n",
    "save_path = os.path.join(os.getcwd(), \"data\", \"clean_tweets.csv\")\n",
    "\n",
    "#df_combined = parallel_apply(df_combined, process_texts)\n",
    "#df_combined['text']=df_combined['text'].swifter.apply(fast_clean_text)\n",
    "df_combined.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\clean_tweets_final.csv\", index=False)"
   ],
   "id": "e2703aeb8311471c",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:00:52.552613Z",
     "start_time": "2025-02-07T12:00:52.432947Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "13a57500b9d77680",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   02401  Borderlands  Positive  \\\n",
      "0   2401  Borderlands  Positive   \n",
      "1   2401  Borderlands  Positive   \n",
      "2   2401  Borderlands  Positive   \n",
      "3   2401  Borderlands  Positive   \n",
      "4   2401  Borderlands  Positive   \n",
      "\n",
      "  im getting on borderlands and i will murder you all ,  \n",
      "0  I am coming to the borders and I will kill you...     \n",
      "1  im getting on borderlands and i will kill you ...     \n",
      "2  im coming on borderlands and i will murder you...     \n",
      "3  im getting on borderlands 2 and i will murder ...     \n",
      "4  im getting into borderlands and i can murder y...     \n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T16:17:44.674520Z",
     "start_time": "2025-02-10T16:17:40.253139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df_clean_tweets = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\clean_tweets_final.csv\")  # Plik bazowy\n",
    "df_final_fixed = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\Final_Fixed_Sentiment_CSV.csv\")\n",
    "df_filtered = df_final_fixed[df_final_fixed[\"sentiment\"] == 2]\n",
    "df_combined = pd.concat([df_clean_tweets, df_filtered], ignore_index=True)\n",
    "print(df_combined['sentiment'].value_counts())\n",
    "df_combined.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\clean_tweets_final.csv\", index=False)\n",
    "\n"
   ],
   "id": "52fd3792d6974014",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4.0    872250\n",
      "0.0    835510\n",
      "2.0     67864\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T16:17:08.276513Z",
     "start_time": "2025-02-10T16:17:05.527903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_next = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\YoutubeCommentsDataSet.csv\") \n",
    "sentiment_mapping = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 2,\n",
    "    \"positive\": 4\n",
    "}\n",
    "df_next[\"Sentiment\"] = df_next[\"Sentiment\"].map(sentiment_mapping)\n",
    "df_next = df_next.rename(columns={\"Comment\":\"text\"})\n",
    "df_next = df_next.rename(columns={\"Sentiment\":\"sentiment\"})\n",
    "print(df_next['sentiment'].value_counts())\n",
    "df_filtr= df_next[df_next[\"sentiment\"] ==2]\n",
    "df_comb = pd.concat([df_clean_tweets,df_filtr], ignore_index=True)\n",
    "print(df_comb['sentiment'].value_counts())\n",
    "df_comb.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\clean_tweets_final.csv\", index=False)\n",
    "\n",
    "\n"
   ],
   "id": "9f6984c922e20589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4    11432\n",
      "2     4638\n",
      "0     2338\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "4.0    872250\n",
      "0.0    835510\n",
      "2.0     59851\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:10:53.206497Z",
     "start_time": "2025-02-10T17:10:51.344903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\clean_tweets_final.csv\") \n",
    "print(s.head())\n",
    "print(s['sentiment'].value_counts())"
   ],
   "id": "9a06ea3bf2fb7439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment\n",
      "0  thats bummer you shoulda got david carr third ...        0.0\n",
      "1  upset he cant update his facebook texting migh...        0.0\n",
      "2  i dived many times ball managed save rest go o...        0.0\n",
      "3            my whole body feels itchy like its fire        0.0\n",
      "4  no its not behaving all im mad why am i here b...        0.0\n",
      "sentiment\n",
      "4.0    872250\n",
      "0.0    835510\n",
      "2.0     67864\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:19:54.371598Z",
     "start_time": "2025-02-10T17:19:54.303679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "last = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\neutral_tweets.csv\") \n",
    "last[\"sentiment\"] =2\n",
    "last.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\neutral_tweets.csv\", index=False)\n",
    "print(last.tail())\n",
    "print(last[\"sentiment\"].value_counts())"
   ],
   "id": "b3b50c36564eff2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                               text  \\\n",
      "20668       20668  overexposed tour maroon cab through eyes drumm...   \n",
      "20669       20669                   wait e news just said its sunday   \n",
      "20670       20670  if only possible part blackpool illuminations ...   \n",
      "20671       20671  no im hilton head till th lol go jason aldean ...   \n",
      "20672       20672  washington reuters us vice president joe biden...   \n",
      "\n",
      "       sentiment  \n",
      "20668          2  \n",
      "20669          2  \n",
      "20670          2  \n",
      "20671          2  \n",
      "20672          2  \n",
      "sentiment\n",
      "2    20673\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:20:10.387585Z",
     "start_time": "2025-02-10T17:20:06.856121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.preprocess import  parallel_apply, process_texts, fast_clean_text\n",
    "import multiprocessing as mp\n",
    "import swifter\n",
    "import os\n",
    "\n",
    "last[\"text\"] = last[\"text\"].fillna(\"\").astype(str)\n",
    "\n",
    "num_cores=mp.cpu_count() // 2\n",
    "last = parallel_apply(last,process_texts, num_cores)\n",
    "#save_path = os.path.join(os.getcwd(), \"data\", \"clean_tweets.csv\")\n",
    "\n",
    "#df_combined = parallel_apply(df_combined, process_texts)\n",
    "last[\"text\"] = last[\"text\"].apply(fast_clean_text)\n",
    "last.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\neutral_tweets.csv\", index=False)\n",
    "\n",
    "print(last[\"text\"].dtype)\n",
    "print(last[\"text\"].head(10))  \n",
    "print(last[\"sentiment\"].value_counts())\n",
    "\n"
   ],
   "id": "aaf977349f8f3500",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    ben smith smith concussion remains out lineup ...\n",
      "1    sorry bout stream last night i crashed out wil...\n",
      "2    chase headleys rbi double th inning off david ...\n",
      "3    cena aj sitting tree kissing st goes ajs job t...\n",
      "4    well said hmw can you now address why texans f...\n",
      "5    just said hello dennis kucinich he walked casu...\n",
      "6    tickets sam smith concert sept cheap flew our ...\n",
      "7    fiorentina have reportedly opened talks chelse...\n",
      "8    what jamie foxx doing sitting next niall like ...\n",
      "9    st uneasyness when he got v defensive about ch...\n",
      "Name: text, dtype: object\n",
      "sentiment\n",
      "2    20673\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:21:47.863119Z",
     "start_time": "2025-02-10T17:21:47.803363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ostatni = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\neutral_tweets.csv\", index_col=0)\n",
    "ostatni.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\neutral_tweets.csv\", index=False)"
   ],
   "id": "a75d84520c311660",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:21:56.023785Z",
     "start_time": "2025-02-10T17:21:56.018796Z"
    }
   },
   "cell_type": "code",
   "source": "print(ostatni.head())",
   "id": "57550af1806442be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         text  sentiment\n",
      "Unnamed: 0                                                              \n",
      "0           ben smith smith concussion remains out lineup ...          2\n",
      "1           sorry bout stream last night i crashed out wil...          2\n",
      "2           chase headleys rbi double th inning off david ...          2\n",
      "3           cena aj sitting tree kissing st goes ajs job t...          2\n",
      "4           well said hmw can you now address why texans f...          2\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:25:17.259320Z",
     "start_time": "2025-02-10T17:25:14.468695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_comb_final = pd.concat([df_clean_tweets,ostatni], ignore_index=True)\n",
    "print(df_comb_final['sentiment'].value_counts())\n",
    "df_comb_final.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\clean_tweets_final.csv\", index=False)\n"
   ],
   "id": "44922a9d4ead3eac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4.0    872250\n",
      "0.0    835510\n",
      "2.0     80524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T17:37:10.400152Z",
     "start_time": "2025-02-10T17:37:09.810381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counts = df_comb_final['sentiment'].value_counts()\n",
    "print(counts)\n",
    "min_count = counts.min()\n",
    "\n",
    "df_0 = df_comb_final[df_comb_final[\"sentiment\"] == 0.0].sample(n=min_count, random_state=42)\n",
    "df_2 = df_comb_final[df_comb_final[\"sentiment\"] == 2.0]  # Wszystkie wiersze, bo to najmniejsza klasa\n",
    "df_4 = df_comb_final[df_comb_final[\"sentiment\"] == 4.0].sample(n=min_count, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_0, df_2, df_4])\n",
    "print(df_balanced.head())\n",
    "print(df_balanced['sentiment'].value_counts())\n",
    "df_balanced = df_balanced.reset_index(drop=True)\n",
    "\n",
    "df_balanced.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\", index=False)"
   ],
   "id": "dfb45b8900c7f1c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4.0    872250\n",
      "0.0    835510\n",
      "2.0     80524\n",
      "Name: count, dtype: int64\n",
      "                                                      text  sentiment\n",
      "629815                   sad about results tonights sytycd        0.0\n",
      "80733    oooh happy th then hehe errr ya i want cooking...        0.0\n",
      "1685215  who announced st nuclear test indira gandhi wh...        0.0\n",
      "229664   cavs its over done magic ampamp penguins ftw b...        0.0\n",
      "522547   they didnt have mojo classic britpop only mojo...        0.0\n",
      "sentiment\n",
      "0.0    80524\n",
      "2.0    80524\n",
      "4.0    80524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T09:24:04.046703Z",
     "start_time": "2025-02-11T09:24:03.143315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df_balanced = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\")\n",
    "print(df_balanced['sentiment'].value_counts())\n",
    "print(df_balanced.head())"
   ],
   "id": "e15fbe571a224e74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0.0    80524\n",
      "2.0    80524\n",
      "4.0    80524\n",
      "Name: count, dtype: int64\n",
      "                                                text  sentiment\n",
      "0                  sad about results tonights sytycd        0.0\n",
      "1  oooh happy th then hehe errr ya i want cooking...        0.0\n",
      "2  who announced st nuclear test indira gandhi wh...        0.0\n",
      "3  cavs its over done magic ampamp penguins ftw b...        0.0\n",
      "4  they didnt have mojo classic britpop only mojo...        0.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T09:57:18.492320Z",
     "start_time": "2025-02-11T09:57:18.057177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üîç Przed czyszczeniem:\", df_balanced.shape[0], \"wierszy\")\n",
    "\n",
    "df_balanced = df_balanced[df_balanced[\"text\"].str.strip() != \"\"]\n",
    "df_balanced = df_balanced.dropna(subset=[\"text\"])\n",
    "\n",
    "print(\"Po czyszczeniu:\", df_balanced.shape[0], \"wierszy\")\n",
    "\n",
    "\n",
    "print(df_balanced[\"text\"].dtype)\n",
    "print(df_balanced[\"text\"].head(10))  # Wy≈õwietl pierwsze warto≈õci w kolumnie \"text\"\n",
    "print(df_balanced[\"sentiment\"].value_counts())\n",
    "df_balanced.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\", index=False)\n"
   ],
   "id": "51c01a397d35889b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Przed czyszczeniem: 240951 wierszy\n",
      "‚úÖ Po czyszczeniu: 240951 wierszy\n",
      "object\n",
      "0                    sad about results tonights sytycd\n",
      "1    oooh happy th then hehe errr ya i want cooking...\n",
      "2    who announced st nuclear test indira gandhi wh...\n",
      "3    cavs its over done magic ampamp penguins ftw b...\n",
      "4    they didnt have mojo classic britpop only mojo...\n",
      "5    twittering looked house today made offer saw b...\n",
      "6    racing i flatted half way through rejoined bun...\n",
      "7    possibly worst site i have ever seen i suck we...\n",
      "8    expecting my mbp back morning applecare had le...\n",
      "9    i read quotflquot florida btw i expected you s...\n",
      "Name: text, dtype: object\n",
      "sentiment\n",
      "0.0    80357\n",
      "4.0    80302\n",
      "2.0    80292\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:47:03.686576Z",
     "start_time": "2025-02-11T10:46:58.683211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.preprocess import  parallel_apply, process_texts, fast_clean_text\n",
    "import multiprocessing as mp\n",
    "import swifter\n",
    "import os\n",
    "\n",
    "#df_balanced[\"text\"] = last[\"text\"].fillna(\"\").astype(str)\n",
    "\n",
    "num_cores=mp.cpu_count() // 2\n",
    "df_balanced = parallel_apply(df_balanced,process_texts, num_cores)\n",
    "#save_path = os.path.join(os.getcwd(), \"data\", \"clean_tweets.csv\")\n",
    "\n",
    "#df_combined = parallel_apply(df_combined, process_texts)\n",
    "df_balanced[\"text\"] = df_balanced[\"text\"].apply(fast_clean_text)\n",
    "df_balanced.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced4Ml.csv\", index=False)\n",
    "\n",
    "print(df_balanced[\"text\"].dtype)\n",
    "print(df_balanced[\"text\"].head(10))  # Wy≈õwietl pierwsze warto≈õci w kolumnie \"text\"\n",
    "print(df_balanced[\"sentiment\"].value_counts())\n"
   ],
   "id": "8e772d52b2b19f61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0                    sad about results tonights sytycd\n",
      "1    oooh happy th then hehe errr ya want cooking l...\n",
      "2    who announced st nuclear test indira gandhi wh...\n",
      "3    cavs its over done magic ampamp penguins ftw b...\n",
      "4    they didnt mojo classic britpop only mojo king...\n",
      "5    twittering looked house today made offer saw b...\n",
      "6    racing flatted half way through rejoined bunch...\n",
      "7    possibly worst site ever seen suck web design ...\n",
      "8    expecting mbp back morning applecare had less ...\n",
      "9    read quotflquot florida btw expected say quotn...\n",
      "Name: text, dtype: object\n",
      "sentiment\n",
      "0.0    80357\n",
      "4.0    80302\n",
      "2.0    80292\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T10:55:12.018785Z",
     "start_time": "2025-02-11T10:55:11.589593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üîç Przed czyszczeniem:\", df_balanced.shape[0], \"wierszy\")\n",
    "\n",
    "df_balanced = df_balanced[df_balanced[\"text\"].str.strip() != \"\"]\n",
    "df_balanced = df_balanced.dropna(subset=[\"text\"])\n",
    "\n",
    "print(\"Po czyszczeniu:\", df_balanced.shape[0], \"wierszy\")\n",
    "\n",
    "\n",
    "print(df_balanced[\"text\"].dtype)\n",
    "print(df_balanced[\"text\"].head(10))  # Wy≈õwietl pierwsze warto≈õci w kolumnie \"text\"\n",
    "print(df_balanced[\"sentiment\"].value_counts())\n",
    "df_balanced.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced4ML.csv\", index=False)\n"
   ],
   "id": "617bc2c7de014ec7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Przed czyszczeniem: 240925 wierszy\n",
      "‚úÖ Po czyszczeniu: 240925 wierszy\n",
      "object\n",
      "0                    sad about results tonights sytycd\n",
      "1    oooh happy th then hehe errr ya want cooking l...\n",
      "2    who announced st nuclear test indira gandhi wh...\n",
      "3    cavs its over done magic ampamp penguins ftw b...\n",
      "4    they didnt mojo classic britpop only mojo king...\n",
      "5    twittering looked house today made offer saw b...\n",
      "6    racing flatted half way through rejoined bunch...\n",
      "7    possibly worst site ever seen suck web design ...\n",
      "8    expecting mbp back morning applecare had less ...\n",
      "9    read quotflquot florida btw expected say quotn...\n",
      "Name: text, dtype: object\n",
      "sentiment\n",
      "0.0    80351\n",
      "2.0    80289\n",
      "4.0    80285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T14:54:12.407703Z",
     "start_time": "2025-02-11T14:54:11.865698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Zapisujemy oczyszczony plik (opcjonalnie)\n",
    "df6= pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\")\n",
    "df_filtro = df6[~df6[\"text\"].str.contains(r\"\\bmodi\\b\", case=False, na=False)]\n",
    "\n",
    "original_len = len(df6)\n",
    "\n",
    "removed_rows = original_len - len(df_filtro)\n",
    "print(f\"Usuniƒôto {removed_rows} wierszy zawierajƒÖcych 'modi'.\")\n",
    "\n",
    "# PodglƒÖd danych\n",
    "\n",
    "\n",
    "print(df_filtro['sentiment'].value_counts())\n",
    "df.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\",index=False)\n"
   ],
   "id": "f3275992b417448d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuniƒôto 58 wierszy zawierajƒÖcych 'modi'.\n",
      "sentiment\n",
      "4.0    33832\n",
      "2.0    19801\n",
      "0.0    12480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T14:41:02.710173Z",
     "start_time": "2025-02-11T14:41:02.421831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csv_files = [r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\1.csv\", r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\2.csv\", r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\3.csv\", r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\4.csv\"]\n",
    "df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "print(df['sentiment'].value_counts())\n",
    "df.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\combined1234.csv\",index=False)\n",
    "\n"
   ],
   "id": "e24e23de0a9edb7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4.0    33844\n",
      "2.0    19821\n",
      "0.0    12482\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T14:52:56.794543Z",
     "start_time": "2025-02-11T14:52:56.548285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\")\n",
    "b = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\combined1234.csv\")\n",
    "\n",
    "#csv_files=[r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\balanced.csv\", r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\combined1234.csv\"]\n",
    "#dfsigma = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "print(a['sentiment'].value_counts())\n",
    "print(\"aaa\")\n",
    "print(b['sentiment'].value_counts())"
   ],
   "id": "e634bb8c38c5b24a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "4.0    33844\n",
      "2.0    19821\n",
      "0.0    12482\n",
      "Name: count, dtype: int64\n",
      "aaa\n",
      "sentiment\n",
      "4.0    33844\n",
      "2.0    19821\n",
      "0.0    12482\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:15:42.465146Z",
     "start_time": "2025-02-12T10:15:41.115409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "c = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\zbalansowanebezmondi.csv\")\n",
    "e = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\combined1234.csv\")\n",
    "g=pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\odczata.csv\")\n",
    "\n",
    "\n",
    "#g.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\odczata.csv\",index=False)\n",
    "\n",
    "df2_filtered = e[e[\"sentiment\"] == 2]\n",
    "df_combined = pd.concat([c, df2_filtered,g], ignore_index=True)\n",
    "print(df_combined[\"sentiment\"].value_counts())\n",
    "\n",
    "mask = df_combined[\"text\"].str.contains(\"global|warming|change|climate\", case=False, na=False)\n",
    "\n",
    "# Je≈õli jest wiƒôcej ni≈º 3000 takich wierszy, usu≈Ñ losowe 3000\n",
    "if mask.sum() > 3000:\n",
    "    to_remove = df_combined[mask].sample(n=5000, random_state=42).index\n",
    "    df_combined = df_combined.drop(index=to_remove)\n",
    "\n",
    "\n",
    "min_count = df_combined[\"sentiment\"].value_counts().min()  # 54,776\n",
    "\n",
    "df_balanced = df_combined.groupby(\"sentiment\").apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(df_balanced[\"sentiment\"].value_counts())\n",
    "\n",
    "df_balanced.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\zbalansowanebezprezydenta.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "216a2e7ec0da9700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0.0    77637\n",
      "4.0    74826\n",
      "2.0    64776\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3640\\140299126.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df_combined.groupby(\"sentiment\").apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0.0    60147\n",
      "2.0    60147\n",
      "4.0    60147\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T10:21:44.651949Z",
     "start_time": "2025-02-12T10:21:39.774019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.preprocess import  parallel_apply, process_texts, fast_clean_text\n",
    "import multiprocessing as mp\n",
    "import swifter\n",
    "import os\n",
    "e = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\data\\zbalansowanebezprezydenta.csv\")\n",
    "\n",
    "\n",
    "e[\"text\"] = e[\"text\"].fillna(\"\").astype(str)\n",
    "\n",
    "\n",
    "num_cores=mp.cpu_count() // 2\n",
    "e = parallel_apply(e,process_texts, num_cores)\n",
    "#save_path = os.path.join(os.getcwd(), \"data\", \"clean_tweets.csv\")\n",
    "\n",
    "#df_combined = parallel_apply(df_combined, process_texts)\n",
    "e[\"text\"] = e[\"text\"].apply(fast_clean_text)\n",
    "\n",
    "e = e[e[\"text\"].str.strip() != \"\"]\n",
    "\n",
    "e.to_csv(r\"C:\\Users\\User\\PycharmProjects\\sentiment\\finaldata\\przefiltrowanebezprezydentapowinnobycokdlaprostych.csv\", index=False)\n",
    "\n",
    "print(e[\"text\"].dtype)\n",
    "print(e[\"text\"].head(10))  # Wy≈õwietl pierwsze warto≈õci w kolumnie \"text\"\n",
    "print(e[\"sentiment\"].value_counts())"
   ],
   "id": "54b88a26128ac1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0                                  hug need hurt anyone\n",
      "1                             evening shift till oclock\n",
      "2                                          urgh doctors\n",
      "3                                           oh stressed\n",
      "5     pt awesomeclasses dayfinishing report gymmiss ...\n",
      "6               wish sold time let know would love hear\n",
      "7     played pokemon weekend ignored twitter totally...\n",
      "8                                        going miss job\n",
      "9                                            meim going\n",
      "10                   hard watch seems incredibly unfair\n",
      "Name: text, dtype: object\n",
      "sentiment\n",
      "0.0    59796\n",
      "4.0    59740\n",
      "2.0    59710\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43f7c59fed1b7f94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
